import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler,OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.compose import ColumnTransformer # Import ColumnTransformer

data = pd.read_csv('/content/Zomato-data- (1).csv')
print(data)
print("-----------------------------------DATA PREPROCESSING--------------------------------------\n")

dat = data.dropna()  # handling missing values
# After dropna()

# Drop 'name' column
data2 = dat.drop(['name'], axis=1)

print(data2.head(10))
print(data2.tail(10))
print(data2.info())

# Convert 'online_order' and 'book_table' to numerical using map
data2['online_order'] = data2['online_order'].map({'Yes': 1, 'No': 0})
data2['book_table'] = data2['book_table'].map({'Yes': 1, 'No': 0}) # Convert 'book_table' to numerical

print("---STANDARDISING-THE DATA-BY-REMOVING-THE-MEAN-AND-SCALING-TO-UNIT-VARIANCE----\n")
print(data2.columns)

scaler = StandardScaler()
# rate values that contain '/'
data2 = data2[data2['rate'].str.contains('/')]

#  split and convert to float
data2['rate'] = data2['rate'].str.split('/').str[0].astype(float)

numeric_cols = ['rate', 'votes', 'approx_cost(for two people)']
categorical_cols = [ 'listed_in(type)'] # Define categorical columns

# Create a ColumnTransformer to apply different preprocessing to different columns
preprocessor = ColumnTransformer(
    transformers=[
        ('num', scaler, numeric_cols),
        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_cols), # One-hot encode categorical columns
    ])

X =  data2[['rate', 'votes', 'approx_cost(for two people)',  'listed_in(type)']] # Selecting features for preprocessing
y = data2['online_order']

X = preprocessor.fit_transform(X) # Fit and transform the preprocessor on X
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# scaled_features = scaler.fit_transform(numeric_data) # This line is redundant

print(X_train[:10])  # First 10 rows of your standardized data
print("------------------------------------MODEL BUILDING-----------------------------\n")

model = RandomForestClassifier()
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)

print("Accuracy Score:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
